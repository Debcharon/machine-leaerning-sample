{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transfer Learning for MNIST Classification\n",
    "\n",
    "In this experiment, we will use transfer learning to classify the handwritten digits from the MNIST dataset. Transfer learning is a technique that allows us to reuse a pre-trained model on a new task by fine-tuning its parameters. This can save us time and computational resources, as well as improve the performance of the model.\n",
    "\n",
    "We will use Keras, a high-level neural network library in Python, to implement the transfer learning. We will use the VGG16 model, which is a convolutional neural network that has been pre-trained on the ImageNet dataset, as our base model. We will add a custom head model on top of the base model, which consists of a flatten layer and a dense layer with 10 output units and softmax activation. We will train the head model on the MNIST dataset, while freezing the weights of the base model.\n",
    "\n",
    "We will use the MNIST dataset, which is a famous dataset that contains 60,000 training images and 10,000 test images of handwritten digits from 0 to 9. Each image has a size of 28 x 28 pixels and is grayscale. We will resize and pad the images to 32 x 32 pixels and add three color channels to match the input shape of the VGG16 model. We will also spl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Cl5Jnorcj4j5",
    "outputId": "c79953bd-076e-4340-c06a-b37bb9f84152"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "11490434/11490434 [==============================] - 0s 0us/step\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import mnist\n",
    "\n",
    "# Load MNIST dataset\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LcG42MJ8k3TW",
    "outputId": "b883b5b9-f2f1-42dc-817f-6a25041c9715"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before padding x_train.shape: (60000, 28, 28)\n",
      "After padding x_train.shape: (60000, 32, 32)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "print(\"Before padding x_train.shape:\", x_train.shape)  # Returns (60000, 28, 28)\n",
    "\n",
    "# Pad image dimensions\n",
    "x_train = tf.pad(x_train, [[0, 0], [2,2], [2,2]]) / 255\n",
    "\n",
    "# Print padded image size\n",
    "print(\"After padding x_train.shape:\", x_train.shape)  # Returns (60000, 32, 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2QGqNVGXlrVA",
    "outputId": "1ceebc57-a7db-4481-8518-a2670f40295e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After adding channels x_train.shape: (60000, 32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "# Add image channels\n",
    "x_train = tf.stack([x_train] * 3, axis=-1)\n",
    "\n",
    "# Print image dimensions after adding channels\n",
    "print(\"After adding channels x_train.shape:\", x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "KC90RcwDl0kH"
   },
   "outputs": [],
   "source": [
    "# Use the last 2000 images as validation set\n",
    "x_val = x_train[-2000:]\n",
    "y_val = y_train[-2000:]\n",
    "\n",
    "# Use the rest of the images as training set\n",
    "x_train = x_train[:-2000]\n",
    "y_train = y_train[:-2000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3I-1ZqfAl8-4",
    "outputId": "426288c9-22c2-4d47-9813-ae8cb6764273"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "58889256/58889256 [==============================] - 0s 0us/step\n",
      "Model: \"vgg16\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, 32, 32, 64)        1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 32, 32, 64)        36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 16, 16, 64)        0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 16, 16, 128)       73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 16, 16, 128)       147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 8, 8, 128)         0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 8, 8, 256)         295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 8, 8, 256)         590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 8, 8, 256)         590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 4, 4, 256)         0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 4, 4, 512)         1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 4, 4, 512)         2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 4, 4, 512)         2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 2, 2, 512)         0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 2, 2, 512)         2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 2, 2, 512)         2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 2, 2, 512)         2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 1, 1, 512)         0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 14,714,688\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Build base model\n",
    "base_model = tf.keras.applications.VGG16(weights='imagenet', include_top=False, input_shape=(32, 32, 3))\n",
    "\n",
    "# Print base model structure information\n",
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "oEp9LJqTmEAi"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers, Model, losses\n",
    "\n",
    "# Flatten base model output\n",
    "x = layers.Flatten()(base_model.output)\n",
    "\n",
    "# Define dense layer\n",
    "x = layers.Dense(10, activation='softmax')(x)\n",
    "\n",
    "# Build complete model\n",
    "head_model = Model(inputs=base_model.input, outputs=x)\n",
    "\n",
    "# Configure training parameters\n",
    "head_model.compile(optimizer='adam',\n",
    "                   loss=losses.sparse_categorical_crossentropy,\n",
    "                   metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lxoQoQyqmLWE",
    "outputId": "750738f4-22a7-49e3-b03c-5da656d07722"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "907/907 [==============================] - 47s 35ms/step - loss: 0.4735 - accuracy: 0.8349 - val_loss: 0.0748 - val_accuracy: 0.9860\n",
      "Epoch 2/10\n",
      "907/907 [==============================] - 31s 34ms/step - loss: 0.0787 - accuracy: 0.9800 - val_loss: 0.0472 - val_accuracy: 0.9930\n",
      "Epoch 3/10\n",
      "907/907 [==============================] - 30s 34ms/step - loss: 0.0773 - accuracy: 0.9837 - val_loss: 0.0404 - val_accuracy: 0.9920\n",
      "Epoch 4/10\n",
      "907/907 [==============================] - 31s 34ms/step - loss: 0.0529 - accuracy: 0.9881 - val_loss: 0.0399 - val_accuracy: 0.9905\n",
      "Epoch 5/10\n",
      "907/907 [==============================] - 31s 34ms/step - loss: 0.0469 - accuracy: 0.9893 - val_loss: 0.0355 - val_accuracy: 0.9920\n",
      "Epoch 6/10\n",
      "907/907 [==============================] - 31s 34ms/step - loss: 0.0476 - accuracy: 0.9898 - val_loss: 0.0595 - val_accuracy: 0.9890\n",
      "Epoch 7/10\n",
      "907/907 [==============================] - 31s 34ms/step - loss: 0.0453 - accuracy: 0.9899 - val_loss: 0.0280 - val_accuracy: 0.9955\n",
      "Epoch 8/10\n",
      "907/907 [==============================] - 31s 34ms/step - loss: 0.0310 - accuracy: 0.9930 - val_loss: 0.0435 - val_accuracy: 0.9945\n",
      "Epoch 9/10\n",
      "907/907 [==============================] - 31s 34ms/step - loss: 0.0396 - accuracy: 0.9913 - val_loss: 0.0322 - val_accuracy: 0.9960\n",
      "Epoch 10/10\n",
      "907/907 [==============================] - 31s 34ms/step - loss: 0.0303 - accuracy: 0.9939 - val_loss: 0.0320 - val_accuracy: 0.9945\n"
     ]
    }
   ],
   "source": [
    "# Train model\n",
    "batch_size = 64\n",
    "epochs = 10\n",
    "history = head_model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oMulBW2umSdO",
    "outputId": "df3d16b0-9eb5-43c9-cbd0-e3574c7b3a4d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 - 1s - loss: 0.0293 - accuracy: 0.9952 - 1s/epoch - 8ms/step\n",
      "63/63 [==============================] - 1s 8ms/step - loss: 0.0320 - accuracy: 0.9945\n",
      "loss: 0.0293 - accuracy: 0.9952\n",
      "Validation loss: 0.0320 - Validation accuracy: 0.9945\n"
     ]
    }
   ],
   "source": [
    "# Select last 5000 test samples\n",
    "x_test_selected = x_test[5000:]\n",
    "y_test_selected = y_test[-5000:]\n",
    "\n",
    "# Pad test images dimensions\n",
    "x_test_selected = tf.pad(x_test_selected, [[0, 0], [2, 2], [2, 2]]) / 255\n",
    "\n",
    "# Add test images channels\n",
    "x_test_selected = tf.stack([x_test_selected] * 3, axis=-1)\n",
    "\n",
    "# Test model performance\n",
    "test_loss, test_accuracy = head_model.evaluate(x_test_selected, y_test_selected, verbose=2)\n",
    "val_loss, val_accuracy = head_model.evaluate(x_val, y_val, verbose=1)\n",
    "\n",
    "# Print test results\n",
    "print(\"loss: {:.4f} - accuracy: {:.4f}\".format(test_loss, test_accuracy))\n",
    "print(\"Validation loss: {:.4f} - Validation accuracy: {:.4f}\".format(val_loss, val_accuracy))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
